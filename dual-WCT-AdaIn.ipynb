{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cfa1fbe-689f-4b30-ae13-ab98aa5ae5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.utils.data as data\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "390bfa48-e4f9-40d3-b85b-093092538922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\"])\n",
    "\n",
    "def default_loader(path):\n",
    "    return Image.open(path).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97222d7a-e0d1-41ba-ad50-0c34c072cb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path, new_size):\n",
    "    img = Image.open(path).convert(mode='RGB')\n",
    "    if new_size:\n",
    "        # for fixed-size squared resizing, leave only the following line uncommented in this if statement\n",
    "        # img = transforms.Resize(img, (new_size, new_size), PIL.Image.BICUBIC)\n",
    "        # img = transforms.Resize((new_size, new_size), interpolation=Image.BICUBIC)(img)\n",
    "        width, height = img.size\n",
    "        max_dim_ix = np.argmax(img.size)\n",
    "        if max_dim_ix == 0:\n",
    "            new_shape = (int(new_size * (height / width)), new_size)\n",
    "            img = transforms.Resize(new_shape, interpolation=Image.BICUBIC)(img)\n",
    "        else:\n",
    "            new_shape = (new_size, int(new_size * (width / height)))\n",
    "            img = transforms.Resize(new_shape, interpolation=Image.BICUBIC)(img)\n",
    "    return transforms.ToTensor()(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a774b592-5a6a-4ddb-a1cd-56d2ef972c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea9658b6-68f7-4824-806b-81914bbaa2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "contentImgPath = r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\Content Images\\tubingen.jpg\"\n",
    "styleImgPath = r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\Style Images\\023.jpg\"\n",
    "fineSize = 512\n",
    "# image_list = [x for x in listdir(contentPath) if is_image_file(x)]\n",
    "# prep = transforms.Compose([\n",
    "#     transforms.Resize((fineSize, fineSize)),  # Use Resize instead of Scale\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "alpha = 0.5\n",
    "contentImg = load_img(contentImgPath,fineSize)\n",
    "styleImg = load_img(styleImgPath,fineSize)\n",
    "\n",
    "# w,h = contentImg.size\n",
    "\n",
    "# if(w > h):\n",
    "#     if(w != fineSize):\n",
    "#         neww = fineSize\n",
    "#         newh = int(h*neww/w)\n",
    "#         contentImg = contentImg.resize((neww,newh))\n",
    "        # styleImg = styleImg.resize((neww,newh))\n",
    "# else:\n",
    "#     if(h != fineSize):\n",
    "#         newh = fineSize\n",
    "#         neww = int(w*newh/h)\n",
    "#         contentImg = contentImg.resize((neww,newh))\n",
    "#         styleImg = styleImg.resize((neww,newh))\n",
    "\n",
    "# contentImg = prep(contentImg)\n",
    "# styleImg = prep(styleImg)\n",
    "\n",
    "\n",
    "# contentImg = transforms.ToTensor()(contentImg)\n",
    "# styleImg = transforms.ToTensor()(styleImg)\n",
    "# contentImg.squeeze(0),styleImg.squeeze(0)\n",
    "# contentImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fa57c68-130b-46f2-bea3-5f8a0e5c8178",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_invertor_conv1_1 = nn.Sequential( # Sequential,\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,3,(3, 3)),\n",
    ")\n",
    "vgg_normalised_conv1_1 = nn.Sequential( # Sequential,\n",
    "\tnn.Conv2d(3,3,(1, 1)),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(3,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    ")\n",
    "feature_invertor_conv2_1 = nn.Sequential( # Sequential,\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.UpsamplingNearest2d(scale_factor=2),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,3,(3, 3)),\n",
    ")\n",
    "vgg_normalised_conv2_1 = nn.Sequential( # Sequential,\n",
    "\tnn.Conv2d(3,3,(1, 1)),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(3,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.MaxPool2d((2, 2),(2, 2),(0, 0),ceil_mode=True),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    ")\n",
    "feature_invertor_conv3_1 = nn.Sequential( # Sequential,\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.UpsamplingNearest2d(scale_factor=2),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.UpsamplingNearest2d(scale_factor=2),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,3,(3, 3)),\n",
    ")\n",
    "vgg_normalised_conv3_1 = nn.Sequential( # Sequential,\n",
    "\tnn.Conv2d(3,3,(1, 1)),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(3,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.MaxPool2d((2, 2),(2, 2),(0, 0),ceil_mode=True),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.MaxPool2d((2, 2),(2, 2),(0, 0),ceil_mode=True),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    ")\n",
    "feature_invertor_conv4_1 = nn.Sequential( # Sequential,\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(512,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.UpsamplingNearest2d(scale_factor=2),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.UpsamplingNearest2d(scale_factor=2),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.UpsamplingNearest2d(scale_factor=2),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,3,(3, 3)),\n",
    ")\n",
    "vgg_normalised_conv4_1 = nn.Sequential( # Sequential,\n",
    "\tnn.Conv2d(3,3,(1, 1)),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(3,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.MaxPool2d((2, 2),(2, 2),(0, 0),ceil_mode=True),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.MaxPool2d((2, 2),(2, 2),(0, 0),ceil_mode=True),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.MaxPool2d((2, 2),(2, 2),(0, 0),ceil_mode=True),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,512,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    ")\n",
    "feature_invertor_conv5_1 = nn.Sequential( # Sequential,\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(512,512,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.UpsamplingNearest2d(scale_factor=2),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(512,512,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(512,512,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(512,512,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(512,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "    nn.UpsamplingNearest2d(scale_factor=2),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "    nn.UpsamplingNearest2d(scale_factor=2),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "    nn.UpsamplingNearest2d(scale_factor=2),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,3,(3, 3)),\n",
    ")\n",
    "vgg_normalised_conv5_1 = nn.Sequential( # Sequential,\n",
    "\tnn.Conv2d(3,3,(1, 1)),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(3,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.MaxPool2d((2, 2),(2, 2),(0, 0),ceil_mode=True),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.MaxPool2d((2, 2),(2, 2),(0, 0),ceil_mode=True),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.MaxPool2d((2, 2),(2, 2),(0, 0),ceil_mode=True),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,512,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(512,512,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(512,512,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(512,512,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.MaxPool2d((2, 2),(2, 2),(0, 0),ceil_mode=True),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(512,512,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6312f1d-b6cb-443f-b530-f1c866a2fe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import torch\n",
    "import torchfile\n",
    "# from torch.utils.serialization import load_lua\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ce3af4c-3b9b-4857-bd16-a538af8fa87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, depth):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        assert(type(depth).__name__ == 'int' and 1 <= depth <= 5)\n",
    "        self.depth = depth\n",
    "\n",
    "        if depth == 1:\n",
    "            self.model = vgg_normalised_conv1_1\n",
    "            self.model.load_state_dict(torch.load(r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\encoders and decoders\\models\\vgg_normalised_conv1_1.pth\"))\n",
    "        elif depth == 2:\n",
    "            self.model = vgg_normalised_conv2_1\n",
    "            self.model.load_state_dict(torch.load(r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\encoders and decoders\\models\\vgg_normalised_conv2_1.pth\"))\n",
    "        elif depth == 3:\n",
    "            self.model = vgg_normalised_conv3_1\n",
    "            self.model.load_state_dict(torch.load(r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\encoders and decoders\\models\\vgg_normalised_conv3_1.pth\"))\n",
    "        elif depth == 4:\n",
    "            self.model = vgg_normalised_conv4_1\n",
    "            self.model.load_state_dict(torch.load(r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\encoders and decoders\\models\\vgg_normalised_conv4_1.pth\"))\n",
    "        elif depth == 5:\n",
    "            self.model = vgg_normalised_conv5_1\n",
    "            self.model.load_state_dict(torch.load(r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\encoders and decoders\\models\\vgg_normalised_conv5_1.pth\"))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, depth):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        assert (type(depth).__name__ == 'int' and 1 <= depth <= 5)\n",
    "        self.depth = depth\n",
    "\n",
    "        if depth == 1:\n",
    "            self.model = feature_invertor_conv1_1\n",
    "            self.model.load_state_dict(torch.load(r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\encoders and decoders\\models\\feature_invertor_conv1_1.pth\"))\n",
    "        elif depth == 2:\n",
    "            self.model = feature_invertor_conv2_1\n",
    "            self.model.load_state_dict(torch.load(r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\encoders and decoders\\models\\feature_invertor_conv2_1.pth\"))\n",
    "        elif depth == 3:\n",
    "            self.model = feature_invertor_conv3_1\n",
    "            self.model.load_state_dict(torch.load(r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\encoders and decoders\\models\\feature_invertor_conv3_1.pth\"))\n",
    "        elif depth == 4:\n",
    "            self.model = feature_invertor_conv4_1\n",
    "            self.model.load_state_dict(torch.load(r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\encoders and decoders\\models\\feature_invertor_conv4_1.pth\"))\n",
    "        elif depth == 5:\n",
    "            self.model = feature_invertor_conv5_1\n",
    "            self.model.load_state_dict(torch.load(r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\encoders and decoders\\models\\feature_invertor_conv5_1.pth\"))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "637838ae-0df2-4e41-9167-bdd8ba6ffc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = Encoder(1)\n",
    "e2 = Encoder(2)\n",
    "e3 = Encoder(3)\n",
    "e4 = Encoder(4)\n",
    "e5 = Encoder(5)\n",
    "\n",
    "d1 = Decoder(1)\n",
    "d2 = Decoder(2)\n",
    "d3 = Decoder(3)\n",
    "d4 = Decoder(4)\n",
    "d5 = Decoder(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e44a81d-2e9d-4f90-8259-c1e28e4d33cd",
   "metadata": {},
   "outputs": [],
   "source": [
    " def whiten_and_color(cF,sF):\n",
    "        cFSize = cF.size()\n",
    "        c_mean = torch.mean(cF,1) # c x (h x w)\n",
    "        c_mean = c_mean.unsqueeze(1).expand_as(cF)\n",
    "        cF = cF - c_mean\n",
    "\n",
    "        contentConv = torch.mm(cF,cF.t()).div(cFSize[1]-1) + torch.eye(cFSize[0]).double()\n",
    "        c_u,c_e,c_v = torch.svd(contentConv,some=False)\n",
    "\n",
    "        k_c = cFSize[0]\n",
    "        for i in range(cFSize[0]):\n",
    "            if c_e[i] < 0.00001:\n",
    "                k_c = i\n",
    "                break\n",
    "\n",
    "        sFSize = sF.size()\n",
    "        s_mean = torch.mean(sF,1)\n",
    "        sF = sF - s_mean.unsqueeze(1).expand_as(sF)\n",
    "        styleConv = torch.mm(sF,sF.t()).div(sFSize[1]-1)\n",
    "        s_u,s_e,s_v = torch.svd(styleConv,some=False)\n",
    "\n",
    "        k_s = sFSize[0]\n",
    "        for i in range(sFSize[0]):\n",
    "            if s_e[i] < 0.00001:\n",
    "                k_s = i\n",
    "                break\n",
    "\n",
    "        c_d = (c_e[0:k_c]).pow(-0.5)\n",
    "        step1 = torch.mm(c_v[:,0:k_c],torch.diag(c_d))\n",
    "        step2 = torch.mm(step1,(c_v[:,0:k_c].t()))\n",
    "        whiten_cF = torch.mm(step2,cF)\n",
    "\n",
    "        s_d = (s_e[0:k_s]).pow(0.5)\n",
    "        targetFeature = torch.mm(torch.mm(torch.mm(s_v[:,0:k_s],torch.diag(s_d)),(s_v[:,0:k_s].t())),whiten_cF)\n",
    "        targetFeature = targetFeature + s_mean.unsqueeze(1).expand_as(targetFeature)\n",
    "        return targetFeature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99d47f23-701f-4d89-a8d7-16a42396c0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(cF,sF,csF,alpha):\n",
    "        cF = cF.double()\n",
    "        sF = sF.double()\n",
    "        C,W,H = cF.size(0),cF.size(1),cF.size(2)\n",
    "        _,W1,H1 = sF.size(0),sF.size(1),sF.size(2)\n",
    "        cFView = cF.view(C,-1)\n",
    "        sFView = sF.view(C,-1)\n",
    "\n",
    "        targetFeature = whiten_and_color(cFView,sFView)\n",
    "        targetFeature = targetFeature.view_as(cF)\n",
    "        ccsF = alpha * targetFeature + (1.0 - alpha) * cF\n",
    "        ccsF = ccsF.float().unsqueeze(0)\n",
    "        # print(\"ccsF:\",ccsF.size())\n",
    "        if csF.size(0) == 0:\n",
    "            csF = torch.empty_like(ccsF)\n",
    "        csF.data.resize_(ccsF.size()).copy_(ccsF)\n",
    "        # print(\"csF:\",csF.shape)\n",
    "        return csF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b64f599a-565e-4996-a457-9834d2f72ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as vutils\n",
    "import scipy.misc\n",
    "# from torch.utils.serialization import load_lua\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2a5d0a4-0b5b-4368-8297-007cedb8a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu(x):\n",
    "        return torch.sum(x,(2,3))/(x.shape[2]*x.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ca039d0-2462-4916-a41a-8c85552f8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "        return torch.sqrt((torch.sum((x.permute([2,3,0,1])-mu(x)).permute([2,3,0,1])**2,(2,3))+0.000000023)/(x.shape[2]*x.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56e11302-1148-4e9a-b0fb-c42e9b638792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, y):\n",
    "        return (sigma(y)*((x.permute([2,3,0,1])-mu(x))/sigma(x)) + mu(y)).permute([2,3,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddedd839-9d2c-4e5b-ad45-465ecd555b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 384, 512])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contentImg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56487000-53f3-4cc4-8cc6-92cf0b61879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cF5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3704871-b49d-4fcc-9026-3954ca642dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def styleTransfer(contentImg,styleImg,csF):\n",
    "#5\n",
    "    sF5 = e5(styleImg)\n",
    "    cF5 = e5(contentImg)\n",
    "    # print(cF5.shape)\n",
    "    sF5 = sF5.data.cpu().squeeze(0)\n",
    "    cF5 = cF5.data.cpu().squeeze(0)\n",
    "    csF5 = transform(cF5,sF5,csF,alpha)\n",
    "    # print(csF5.shape)\n",
    "    Im5 = d5(csF5)\n",
    "\n",
    "    print(cF5.shape)\n",
    "\n",
    "    \n",
    "    cF5 = e5(cF5)\n",
    "    sF5 = e5(Im5)\n",
    "    sF5 = sF5.data.cpu().squeeze(0)\n",
    "    cF5 = cF5.data.cpu().squeeze(0)\n",
    "    cF5=cF5.unsqueeze(0)\n",
    "    sF5=sF5.unsqueeze(0)\n",
    "    csF5 = forward(cF5,sF5)\n",
    "    Im5 = d5(csF5)\n",
    "#4\n",
    "    sF4 = e4(styleImg)\n",
    "    cF4 = e4(Im5)\n",
    "    sF4 = sF4.data.cpu().squeeze(0)\n",
    "    cF4 = cF4.data.cpu().squeeze(0)\n",
    "    csF4 = transform(cF4,sF4,csF,alpha)\n",
    "    Im4 = d4(csF4)\n",
    "    # print(Im4.shape)\n",
    "\n",
    "    sF4 = e4(Im4)\n",
    "    cF4 = e4(cF4)\n",
    "    sF4 = sF4.data.cpu().squeeze(0)\n",
    "    cF4 = cF4.data.cpu().squeeze(0)\n",
    "    cF4=cF4.unsqueeze(0)\n",
    "    sF4=sF4.unsqueeze(0)\n",
    "    csF4 = forward(cF4,sF4)\n",
    "    Im4 = d4(csF4)\n",
    "    \n",
    "#3    \n",
    "    sF3 = e3(styleImg)\n",
    "    cF3 = e3(Im4)\n",
    "    sF3 = sF3.data.cpu().squeeze(0)\n",
    "    cF3 = cF3.data.cpu().squeeze(0)\n",
    "    csF3 = transform(cF3,sF3,csF,alpha)\n",
    "    Im3 = d3(csF3)\n",
    "\n",
    "    sF3 = e3(Im3)\n",
    "    cF3 = e3(cF3)\n",
    "    sF3 = sF3.data.cpu().squeeze(0)\n",
    "    cF3 = cF3.data.cpu().squeeze(0)\n",
    "    cF3=cF3.unsqueeze(0)\n",
    "    sF3=sF3.unsqueeze(0)\n",
    "    csF3 = forward(cF3,sF3)\n",
    "    Im3 = d3(csF3)\n",
    "#2\n",
    "    sF2 = e2(styleImg)\n",
    "    cF2 = e2(Im3)\n",
    "    sF2 = sF2.data.cpu().squeeze(0)\n",
    "    cF2 = cF2.data.cpu().squeeze(0)\n",
    "    csF2 = transform(cF2,sF2,csF,alpha)\n",
    "    Im2 = d2(csF2)\n",
    "\n",
    "    sF2 = e2(Im2)\n",
    "    cF2 = e2(cF2)\n",
    "    sF2 = sF2.data.cpu().squeeze(0)\n",
    "    cF2 = cF2.data.cpu().squeeze(0)\n",
    "    cF2=cF2.unsqueeze(0)\n",
    "    sF2=sF2.unsqueeze(0)\n",
    "    csF2 = forward(cF2,sF2)\n",
    "    Im2 = d2(csF2)\n",
    "#1\n",
    "    sF1 = e1(styleImg)\n",
    "    cF1 = e1(Im2)\n",
    "    sF1 = sF1.data.cpu().squeeze(0)\n",
    "    cF1 = cF1.data.cpu().squeeze(0)\n",
    "    csF1 = transform(cF1,sF1,csF,alpha)\n",
    "    Im1 = d1(csF1)\n",
    "\n",
    "    sF1 = e1(Im1)\n",
    "    cF1 = e1(cF1)\n",
    "    sF1 = sF1.data.cpu().squeeze(0)\n",
    "    cF1 = cF1.data.cpu().squeeze(0)\n",
    "    cF1=cF1.unsqueeze(0)\n",
    "    sF1=sF1.unsqueeze(0)\n",
    "    csF1 = forward(cF1,sF1)\n",
    "    Im1 = d1(csF1)\n",
    "\n",
    "    save_path=r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\Output Images\\WCT-AdaIn.png\"\n",
    "    \n",
    "    vutils.save_image(Im1.data.cpu().float(),save_path)\n",
    "    # image_np = Im1.data.cpu().float().numpy()\n",
    "\n",
    "    # plt.imshow(image_np.transpose(1, 2, 0))  # Transpose to (H, W, C) for displaying RGB image\n",
    "    # plt.axis('off')  # Hide axis ticks and labels\n",
    "    # plt.show()\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daa92ce7-e424-40ce-89fb-2b474f289b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 24, 32])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [3, 3, 1, 1], expected input[1, 512, 24, 32] to have 3 channels, but got 512 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 16\u001b[0m\n\u001b[0;32m     11\u001b[0m     csF \u001b[38;5;241m=\u001b[39m Variable(csF)\n\u001b[0;32m     13\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 16\u001b[0m styleTransfer(cImg,sImg,csF)\n\u001b[0;32m     17\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mElapsed time is: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (end_time \u001b[38;5;241m-\u001b[39m start_time))\n",
      "Cell \u001b[1;32mIn[19], line 15\u001b[0m, in \u001b[0;36mstyleTransfer\u001b[1;34m(contentImg, styleImg, csF)\u001b[0m\n\u001b[0;32m     10\u001b[0m Im5 \u001b[38;5;241m=\u001b[39m d5(csF5)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(cF5\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 15\u001b[0m cF5 \u001b[38;5;241m=\u001b[39m e5(cF5)\n\u001b[0;32m     16\u001b[0m sF5 \u001b[38;5;241m=\u001b[39m e5(Im5)\n\u001b[0;32m     17\u001b[0m sF5 \u001b[38;5;241m=\u001b[39m sF5\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 27\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 27\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [3, 3, 1, 1], expected input[1, 512, 24, 32] to have 3 channels, but got 512 channels instead"
     ]
    }
   ],
   "source": [
    "avgTime = 0\n",
    "cImg = torch.Tensor()\n",
    "sImg = torch.Tensor()\n",
    "csF = torch.Tensor()\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    cImg = Variable(contentImg)\n",
    "    sImg = Variable(styleImg)\n",
    "    csF = Variable(csF)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "styleTransfer(cImg,sImg,csF)\n",
    "end_time = time.time()\n",
    "print('Elapsed time is: %f' % (end_time - start_time))\n",
    "avgTime += (end_time - start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab9a56b-2347-454c-a57a-3d6c99a84689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245c24cb-0e9d-40bc-950f-966e6a6dc11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409bd271-1d56-42c8-a0cc-3b44512f398a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13a53fd-b918-4487-ab95-6c8899be7c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
