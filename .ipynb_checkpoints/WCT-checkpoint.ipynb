{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd6adddd-782b-4c32-a5ef-53b4d6fb504d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.backends.cudnn.enabled)  # Should print True if CuDNN is available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cfa1fbe-689f-4b30-ae13-ab98aa5ae5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.utils.data as data\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "390bfa48-e4f9-40d3-b85b-093092538922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\"])\n",
    "\n",
    "def default_loader(path):\n",
    "    return Image.open(path).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bb91b245-4e84-47ba-8d05-301935cbfbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "contentImgPath = r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\Content Images\\05.jpg\"\n",
    "styleImgPath = r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\Style Images\\in4.jpg\"\n",
    "fineSize = 512\n",
    "# image_list = [x for x in listdir(contentPath) if is_image_file(x)]\n",
    "prep = transforms.Compose([\n",
    "    transforms.Resize((fineSize, fineSize)),  # Use Resize instead of Scale\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "alpha = 0.7\n",
    "contentImg = default_loader(contentImgPath)\n",
    "styleImg = default_loader(styleImgPath)\n",
    "\n",
    "w,h = .size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d3f8da49-f4d4-43a1-a351-a283b5d11c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be42b41a-0bd6-41f8-a154-b7ac5875f569",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(w > h):\n",
    "    if(w != fineSize):\n",
    "        neww = fineSize\n",
    "        newh = int(h*neww/w)\n",
    "        contentImg = contentImg.resize((neww,newh))\n",
    "        styleImg = styleImg.resize((neww,newh))\n",
    "else:\n",
    "    if(h != fineSize):\n",
    "        newh = fineSize\n",
    "        neww = int(w*newh/h)\n",
    "        contentImg = contentImg.resize((neww,newh))\n",
    "        styleImg = styleImg.resize((neww,newh))\n",
    "\n",
    "contentImg = transforms.ToTensor()(contentImg)\n",
    "styleImg = transforms.ToTensor()(styleImg)\n",
    "contentImg.squeeze(0),styleImg.squeeze(0)\n",
    "styleImg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3fea48-352b-4b5c-b536-52d7962165ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8fa57c68-130b-46f2-bea3-5f8a0e5c8178",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_invertor_conv1_1 = nn.Sequential( # Sequential,\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,3,(3, 3)),\n",
    ")\n",
    "vgg_normalised_conv1_1 = nn.Sequential( # Sequential,\n",
    "\tnn.Conv2d(3,3,(1, 1)),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(3,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    ")\n",
    "feature_invertor_conv2_1 = nn.Sequential( # Sequential,\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.UpsamplingNearest2d(scale_factor=2),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,3,(3, 3)),\n",
    ")\n",
    "vgg_normalised_conv2_1 = nn.Sequential( # Sequential,\n",
    "\tnn.Conv2d(3,3,(1, 1)),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(3,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.MaxPool2d((2, 2),(2, 2),(0, 0),ceil_mode=True),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    ")\n",
    "feature_invertor_conv3_1 = nn.Sequential( # Sequential,\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.UpsamplingNearest2d(scale_factor=2),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.UpsamplingNearest2d(scale_factor=2),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,3,(3, 3)),\n",
    ")\n",
    "vgg_normalised_conv3_1 = nn.Sequential( # Sequential,\n",
    "\tnn.Conv2d(3,3,(1, 1)),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(3,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.MaxPool2d((2, 2),(2, 2),(0, 0),ceil_mode=True),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.MaxPool2d((2, 2),(2, 2),(0, 0),ceil_mode=True),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    ")\n",
    "feature_invertor_conv4_1 = nn.Sequential( # Sequential,\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(512,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.UpsamplingNearest2d(scale_factor=2),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.UpsamplingNearest2d(scale_factor=2),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.UpsamplingNearest2d(scale_factor=2),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,3,(3, 3)),\n",
    ")\n",
    "vgg_normalised_conv4_1 = nn.Sequential( # Sequential,\n",
    "\tnn.Conv2d(3,3,(1, 1)),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(3,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.MaxPool2d((2, 2),(2, 2),(0, 0),ceil_mode=True),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.MaxPool2d((2, 2),(2, 2),(0, 0),ceil_mode=True),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.MaxPool2d((2, 2),(2, 2),(0, 0),ceil_mode=True),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,512,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    ")\n",
    "feature_invertor_conv5_1 = nn.Sequential( # Sequential,\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(512,512,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.UpsamplingNearest2d(scale_factor=2),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(512,512,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(512,512,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(512,512,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(512,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "    nn.UpsamplingNearest2d(scale_factor=2),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "    nn.UpsamplingNearest2d(scale_factor=2),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "    nn.UpsamplingNearest2d(scale_factor=2),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,3,(3, 3)),\n",
    ")\n",
    "vgg_normalised_conv5_1 = nn.Sequential( # Sequential,\n",
    "\tnn.Conv2d(3,3,(1, 1)),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(3,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,64,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.MaxPool2d((2, 2),(2, 2),(0, 0),ceil_mode=True),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(64,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,128,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.MaxPool2d((2, 2),(2, 2),(0, 0),ceil_mode=True),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(128,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,256,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.MaxPool2d((2, 2),(2, 2),(0, 0),ceil_mode=True),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(256,512,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(512,512,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(512,512,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(512,512,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    "\tnn.MaxPool2d((2, 2),(2, 2),(0, 0),ceil_mode=True),\n",
    "\tnn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "\tnn.Conv2d(512,512,(3, 3)),\n",
    "\tnn.ReLU(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d6312f1d-b6cb-443f-b530-f1c866a2fe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import torch\n",
    "import torchfile\n",
    "# from torch.utils.serialization import load_lua\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1ce3af4c-3b9b-4857-bd16-a538af8fa87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, depth):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        assert(type(depth).__name__ == 'int' and 1 <= depth <= 5)\n",
    "        self.depth = depth\n",
    "\n",
    "        if depth == 1:\n",
    "            self.model = vgg_normalised_conv1_1\n",
    "            self.model.load_state_dict(torch.load(r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\encoders and decoders\\models\\vgg_normalised_conv1_1.pth\"))\n",
    "        elif depth == 2:\n",
    "            self.model = vgg_normalised_conv2_1\n",
    "            self.model.load_state_dict(torch.load(r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\encoders and decoders\\models\\vgg_normalised_conv2_1.pth\"))\n",
    "        elif depth == 3:\n",
    "            self.model = vgg_normalised_conv3_1\n",
    "            self.model.load_state_dict(torch.load(r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\encoders and decoders\\models\\vgg_normalised_conv3_1.pth\"))\n",
    "        elif depth == 4:\n",
    "            self.model = vgg_normalised_conv4_1\n",
    "            self.model.load_state_dict(torch.load(r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\encoders and decoders\\models\\vgg_normalised_conv4_1.pth\"))\n",
    "        elif depth == 5:\n",
    "            self.model = vgg_normalised_conv5_1\n",
    "            self.model.load_state_dict(torch.load(r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\encoders and decoders\\models\\vgg_normalised_conv5_1.pth\"))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, depth):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        assert (type(depth).__name__ == 'int' and 1 <= depth <= 5)\n",
    "        self.depth = depth\n",
    "\n",
    "        if depth == 1:\n",
    "            self.model = feature_invertor_conv1_1\n",
    "            self.model.load_state_dict(torch.load(r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\encoders and decoders\\models\\feature_invertor_conv1_1.pth\"))\n",
    "        elif depth == 2:\n",
    "            self.model = feature_invertor_conv2_1\n",
    "            self.model.load_state_dict(torch.load(r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\encoders and decoders\\models\\feature_invertor_conv2_1.pth\"))\n",
    "        elif depth == 3:\n",
    "            self.model = feature_invertor_conv3_1\n",
    "            self.model.load_state_dict(torch.load(r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\encoders and decoders\\models\\feature_invertor_conv3_1.pth\"))\n",
    "        elif depth == 4:\n",
    "            self.model = feature_invertor_conv4_1\n",
    "            self.model.load_state_dict(torch.load(r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\encoders and decoders\\models\\feature_invertor_conv4_1.pth\"))\n",
    "        elif depth == 5:\n",
    "            self.model = feature_invertor_conv5_1\n",
    "            self.model.load_state_dict(torch.load(r\"C:\\Users\\Jaya Teja\\Universal-Style-Transfer\\encoders and decoders\\models\\feature_invertor_conv5_1.pth\"))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "637838ae-0df2-4e41-9167-bdd8ba6ffc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = Encoder(1)\n",
    "e2 = Encoder(2)\n",
    "e3 = Encoder(3)\n",
    "e4 = Encoder(4)\n",
    "e5 = Encoder(5)\n",
    "\n",
    "d1 = Decoder(1)\n",
    "d2 = Decoder(2)\n",
    "d3 = Decoder(3)\n",
    "d4 = Decoder(4)\n",
    "d5 = Decoder(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7e44a81d-2e9d-4f90-8259-c1e28e4d33cd",
   "metadata": {},
   "outputs": [],
   "source": [
    " def whiten_and_color(cF,sF):\n",
    "        cFSize = cF.size()\n",
    "        c_mean = torch.mean(cF,1) # c x (h x w)\n",
    "        c_mean = c_mean.unsqueeze(1).expand_as(cF)\n",
    "        cF = cF - c_mean\n",
    "\n",
    "        contentConv = torch.mm(cF,cF.t()).div(cFSize[1]-1) + torch.eye(cFSize[0]).double()\n",
    "        c_u,c_e,c_v = torch.svd(contentConv,some=False)\n",
    "\n",
    "        k_c = cFSize[0]\n",
    "        for i in range(cFSize[0]):\n",
    "            if c_e[i] < 0.00001:\n",
    "                k_c = i\n",
    "                break\n",
    "\n",
    "        sFSize = sF.size()\n",
    "        s_mean = torch.mean(sF,1)\n",
    "        sF = sF - s_mean.unsqueeze(1).expand_as(sF)\n",
    "        styleConv = torch.mm(sF,sF.t()).div(sFSize[1]-1)\n",
    "        s_u,s_e,s_v = torch.svd(styleConv,some=False)\n",
    "\n",
    "        k_s = sFSize[0]\n",
    "        for i in range(sFSize[0]):\n",
    "            if s_e[i] < 0.00001:\n",
    "                k_s = i\n",
    "                break\n",
    "\n",
    "        c_d = (c_e[0:k_c]).pow(-0.5)\n",
    "        step1 = torch.mm(c_v[:,0:k_c],torch.diag(c_d))\n",
    "        step2 = torch.mm(step1,(c_v[:,0:k_c].t()))\n",
    "        whiten_cF = torch.mm(step2,cF)\n",
    "\n",
    "        s_d = (s_e[0:k_s]).pow(0.5)\n",
    "        targetFeature = torch.mm(torch.mm(torch.mm(s_v[:,0:k_s],torch.diag(s_d)),(s_v[:,0:k_s].t())),whiten_cF)\n",
    "        targetFeature = targetFeature + s_mean.unsqueeze(1).expand_as(targetFeature)\n",
    "        return targetFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "99d47f23-701f-4d89-a8d7-16a42396c0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(cF,sF,csF,alpha):\n",
    "        cF = cF.double()\n",
    "        sF = sF.double()\n",
    "        C,W,H = cF.size(0),cF.size(1),cF.size(2)\n",
    "        _,W1,H1 = sF.size(0),sF.size(1),sF.size(2)\n",
    "        cFView = cF.view(C,-1)\n",
    "        sFView = sF.view(C,-1)\n",
    "\n",
    "        targetFeature = whiten_and_color(cFView,sFView)\n",
    "        targetFeature = targetFeature.view_as(cF)\n",
    "        ccsF = alpha * targetFeature + (1.0 - alpha) * cF\n",
    "        ccsF = ccsF.float().unsqueeze(0)\n",
    "        csF.data.resize_(ccsF.size()).copy_(ccsF)\n",
    "        return csF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b64f599a-565e-4996-a457-9834d2f72ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as vutils\n",
    "import scipy.misc\n",
    "# from torch.utils.serialization import load_lua\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b3704871-b49d-4fcc-9026-3954ca642dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def styleTransfer(contentImg,styleImg,csF):\n",
    "\n",
    "    sF5 = e5(styleImg)\n",
    "    cF5 = e5(contentImg)\n",
    "    sF5 = sF5.data.cpu().squeeze(0)\n",
    "    cF5 = cF5.data.cpu().squeeze(0)\n",
    "    csF5 = transform(cF5,sF5,csF,alpha)\n",
    "    Im5 = d5(csF5)\n",
    "\n",
    "    sF4 = e4(styleImg)\n",
    "    cF4 = e4(Im5)\n",
    "    sF4 = sF4.data.cpu().squeeze(0)\n",
    "    cF4 = cF4.data.cpu().squeeze(0)\n",
    "    csF4 = transform(cF4,sF4,csF,alpha)\n",
    "    Im4 = d4(csF4)\n",
    "\n",
    "    sF3 = e3(styleImg)\n",
    "    cF3 = e3(Im4)\n",
    "    sF3 = sF3.data.cpu().squeeze(0)\n",
    "    cF3 = cF3.data.cpu().squeeze(0)\n",
    "    csF3 = transform(cF3,sF3,csF,alpha)\n",
    "    Im3 = d3(csF3)\n",
    "\n",
    "    sF2 = e2(styleImg)\n",
    "    cF2 = e2(Im3)\n",
    "    sF2 = sF2.data.cpu().squeeze(0)\n",
    "    cF2 = cF2.data.cpu().squeeze(0)\n",
    "    csF2 = transform(cF2,sF2,csF,alpha)\n",
    "    Im2 = d2(csF2)\n",
    "\n",
    "    sF1 = e1(styleImg)\n",
    "    cF1 = e1(Im2)\n",
    "    sF1 = sF1.data.cpu().squeeze(0)\n",
    "    cF1 = cF1.data.cpu().squeeze(0)\n",
    "    csF1 = transform(cF1,sF1,csF,alpha)\n",
    "    Im1 = d1(csF1)\n",
    "\n",
    "    # vutils.save_image(Im1.data.cpu().float(),os.path.join(args.outf)\n",
    "    image_np = Im1.data.cpu().float().numpy()\n",
    "\n",
    "    plt.imshow(image_np.transpose(1, 2, 0))  # Transpose to (H, W, C) for displaying RGB image\n",
    "    plt.axis('off')  # Hide axis ticks and labels\n",
    "    plt.show()\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "daa92ce7-e424-40ce-89fb-2b474f289b4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Padding length should be less than or equal to two times the input dimension but got padding length 4 and input of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 16\u001b[0m\n\u001b[0;32m     10\u001b[0m     csF \u001b[38;5;241m=\u001b[39m Variable(csF)\n\u001b[0;32m     13\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 16\u001b[0m styleTransfer(cImg,sImg,csF)\n\u001b[0;32m     17\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mElapsed time is: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (end_time \u001b[38;5;241m-\u001b[39m start_time))\n",
      "Cell \u001b[1;32mIn[87], line 8\u001b[0m, in \u001b[0;36mstyleTransfer\u001b[1;34m(contentImg, styleImg, csF)\u001b[0m\n\u001b[0;32m      6\u001b[0m cF5 \u001b[38;5;241m=\u001b[39m cF5\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      7\u001b[0m csF5 \u001b[38;5;241m=\u001b[39m transform(cF5,sF5,csF,alpha)\n\u001b[1;32m----> 8\u001b[0m Im5 \u001b[38;5;241m=\u001b[39m d5(csF5)\n\u001b[0;32m     10\u001b[0m sF4 \u001b[38;5;241m=\u001b[39m e4(styleImg)\n\u001b[0;32m     11\u001b[0m cF4 \u001b[38;5;241m=\u001b[39m e4(Im5)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[79], line 55\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 55\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\padding.py:358\u001b[0m, in \u001b[0;36m_ReflectionPadNd.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreflect\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:4522\u001b[0m, in \u001b[0;36mpad\u001b[1;34m(input, pad, mode, value)\u001b[0m\n\u001b[0;32m   4515\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplicate\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   4516\u001b[0m             \u001b[38;5;66;03m# Use slow decomp whose backward will be in terms of index_put.\u001b[39;00m\n\u001b[0;32m   4517\u001b[0m             \u001b[38;5;66;03m# importlib is required because the import cannot be top level\u001b[39;00m\n\u001b[0;32m   4518\u001b[0m             \u001b[38;5;66;03m# (cycle) and cannot be nested (TS doesn't support)\u001b[39;00m\n\u001b[0;32m   4519\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch._decomp.decompositions\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39m_replication_pad(\n\u001b[0;32m   4520\u001b[0m                 \u001b[38;5;28minput\u001b[39m, pad\n\u001b[0;32m   4521\u001b[0m             )\n\u001b[1;32m-> 4522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, pad, mode, value)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Padding length should be less than or equal to two times the input dimension but got padding length 4 and input of dimension 1"
     ]
    }
   ],
   "source": [
    "avgTime = 0\n",
    "cImg = torch.Tensor()\n",
    "sImg = torch.Tensor()\n",
    "csF = torch.Tensor()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    cImg = Variable(contentImg)\n",
    "    sImg = Variable(styleImg)\n",
    "    csF = Variable(csF)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "styleTransfer(cImg,sImg,csF)\n",
    "end_time = time.time()\n",
    "print('Elapsed time is: %f' % (end_time - start_time))\n",
    "avgTime += (end_time - start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab9a56b-2347-454c-a57a-3d6c99a84689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245c24cb-0e9d-40bc-950f-966e6a6dc11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409bd271-1d56-42c8-a0cc-3b44512f398a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13a53fd-b918-4487-ab95-6c8899be7c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
